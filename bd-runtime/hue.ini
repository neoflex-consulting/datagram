[desktop]

# Set this to a random string, the longer the better.
secret_key=kasdlfjknasdfl3hbaksk3bwkasdfkasdfba23asdf

# Webserver listens on this address and port
http_host=0.0.0.0
http_port=8888

# Time zone name
time_zone=Europe/Moscow

# Enable or disable debug mode.
django_debug_mode=false

# Enable or disable backtrace for server error
http_500_debug_mode=false

app_blacklist=search,hbase,security

# Use gunicorn or not
use_cherrypy_server=false

# Gunicorn work class: gevent or evenlet, gthread or sync.
gunicorn_work_class=sync
gunicorn_number_of_workers=1

[[database]]
engine=postgresql_psycopg2
host=hivemetastore
port=5432
user=postgres
password=new_password
name=hue

[notebook]
[[interpreters]]

[[[Adventureworks]]]
name = Adventureworks
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/Adventureworks"}'

[[[teneo]]]
name = Datagram
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/teneo"}'

[[[HiveMetastore]]]
name = Hive metastore
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/hivemetastoredb"}'

[[[OozieDB]]]
name = Oozie DB
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/oozie_metastore"}'

[[[HueDB]]]
name = Hue DB
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/hue"}'

[[[DWH]]]
name = DWH
interface=sqlalchemy
options='{"url": "postgresql://postgres:new_password@hivemetastore/dwh"}'




            [[[hive]]]
name=Hive
interface=hiveserver2

[[[spark]]]
name=Scala
interface=livy

[[[pyspark]]]
name=PySpark
interface=livy

[[[r]]]
name=R
interface=livy

[[[sparksql]]]
name=Spark SQL
interface=livy

[dashboard]

# Activate the SQL Dashboard (beta).
has_sql_enabled=false



[hadoop]

# Configuration for HDFS NameNode
# ------------------------------------------------------------------------
[[hdfs_clusters]]
[[[default]]]

# Enter the filesystem uri
fs_defaultfs=hdfs://master:8020

# Use WebHdfs/HttpFs as the communication mechanism.
# Domain should be the NameNode or HttpFs host.
# Default port is 14000 for HttpFs.
webhdfs_url=http://master:9870/webhdfs/v1

is_enabled=true

[[yarn_clusters]]
[[[default]]]

# Enter the host on which you are running the ResourceManager
resourcemanager_host=master

# The port where the ResourceManager IPC listens on
resourcemanager_port=8032

# URL of the ResourceManager API
resourcemanager_api_url=http://master:8088

# URL of the ProxyServer API
# proxy_api_url=http://master:8088

# URL of the HistoryServer API
history_server_api_url=http://master:19888

# URL of the Spark History Server
spark_history_server_url=http://master:18080

[beeswax]

# Host where HiveServer2 is running.
# If Kerberos security is enabled, use fully-qualified domain name (FQDN).
hive_server_host=master

# Port where HiveServer2 Thrift server runs on.
hive_server_port=10000

[spark]
# The Livy Server URL.
livy_server_url=http://livy:8998/

# Configure Livy to start in local 'process' mode, or 'yarn' workers.
livy_server_session_kind=yarn

# Whether Livy requires client to perform Kerberos authentication.
security_enabled=false

# Host of the Sql Server
## sql_server_host=localhost

# Port of the Sql Server
## sql_server_port=10000

# Choose whether Hue should validate certificates received from the server.
## ssl_cert_ca_verify=true

[liboozie]
# The URL where the Oozie service runs on. This is required in order for
# users to submit jobs. Empty value disables the config check.
oozie_url=http://oozie:11000/oozie
