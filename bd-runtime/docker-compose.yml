version: "3.7"
services:
  hivemetastore:
    image: postgres:11.5
    restart: always
    command: postgres -c max_connections=500
    hostname: hivemetastore
    environment:
      POSTGRES_PASSWORD: new_password
    ports:
      - 5432:5432
    expose:
      - 5432
    volumes:
      - ./pg-init.sql:/docker-entrypoint-initdb.d/pg-init.sql
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      bd_net:
        ipv4_address: 10.20.1.4

  master:
    image: neoflexdatagram/bd-base
    build: ./bd-base
    hostname: master
    depends_on:
      - hivemetastore
    environment:
      HADOOP_NODE: namenode
      HIVE_CONFIGURE: yes, please
      SPARK_PUBLIC_DNS: localhost
      SPARK_LOCAL_IP: 10.20.1.1
      SPARK_MASTER_HOST: 10.20.1.1
      SPARK_LOCAL_HOSTNAME: master
    expose:
      - 1-65535
    ports:
      # Spark Master Web UI
      - 8080:8080
      # Spark job Web UI: increments for each successive job
      - 4040:4040
      - 4041:4041
      - 4042:4042
      - 4043:4043
      # Spark History server
      - 18080:18080
      # YARN UI
      - 8088:8088
      # Hadoop namenode UI
      - 9870:9870
      # Hadoop secondary namenode UI
      - 9868:9868
      # Hive JDBC
      - 10000:10000
      # webhdfs
      - 51070:50070
      # others
      - 8030:8030
      - 8031:8031
      - 8032:8032
      - 8033:8033
      - 9000:9000
      - 7077:7077
      - 19888:19888
    volumes:
      - dfs_name:/dfs/name
      - ./bd-base/data:/data
#      - ./bd-base/extralib:/extralib
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/extralib/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/extralib/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ./bd-base/conf/hadoop/core-site.xml:/usr/hadoop/etc/hadoop/core-site.xml
#      - ./bd-base/conf/hadoop/yarn-site.xml:/usr/hadoop/etc/hadoop/yarn-site.xml
#      - ./bd-base/conf/spark/spark-defaults.conf:/usr/spark/conf/spark-defaults.conf
    networks:
      bd_net:
        ipv4_address: 10.20.1.1
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"
      - "zookeeper:10.20.1.9"
      - "kafka:10.20.1.10"

  worker1:
    image: neoflexdatagram/bd-base
    build: ./bd-base
    hostname: worker1
    depends_on:
      - hivemetastore
    environment:
      SPARK_MASTER_ADDRESS: spark://master:7077
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARK_LOCAL_HOSTNAME: worker1
      SPARK_LOCAL_IP: 10.20.1.2
      SPARK_MASTER_HOST: 10.20.1.1
      HADOOP_NODE: datanode
    expose:
      - 1-65535
    ports:
      # Hadoop datanode UI
      - 9864:9864
      #Spark worker UI
      - 8081:8081
      - 8042:8042
    volumes:
      - dfs_data_1:/dfs/data
      - ./bd-base/data:/data
#      - ./bd-base/extralib:/extralib
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/extralib/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/extralib/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ./bd-base/conf/hadoop/core-site.xml:/usr/hadoop/etc/hadoop/core-site.xml
#      - ./bd-base/conf/hadoop/yarn-site.xml:/usr/hadoop/etc/hadoop/yarn-site.xml
#      - ./bd-base/conf/spark/spark-defaults.conf:/usr/spark/conf/spark-defaults.conf
    networks:
      bd_net:
        ipv4_address: 10.20.1.2
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"
      - "zookeeper:10.20.1.9"
      - "kafka:10.20.1.10"

  worker2:
    image: neoflexdatagram/bd-base
    build: ./bd-base
    hostname: worker2
    depends_on:
      - hivemetastore
    environment:
      SPARK_MASTER_ADDRESS: spark://master:7077
      SPARK_WORKER_PORT: 8882
      SPARK_WORKER_WEBUI_PORT: 8082
      SPARK_PUBLIC_DNS: localhost
      SPARK_LOCAL_HOSTNAME: worker2
      SPARK_LOCAL_IP: 10.20.1.3
      SPARK_MASTER_HOST: 10.20.1.1
      HADOOP_NODE: datanode
      HADOOP_DATANODE_UI_PORT: 9865
    expose:
      - 1-65535
    ports:
      # Hadoop datanode UI
      - 9865:9865
      # Spark worker UI
      - 8082:8082
      - 8043:8042
    volumes:
      - dfs_data_2:/dfs/data
      - ./bd-base/data:/data
#      - ./bd-base/extralib:/extralib
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/extralib/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/extralib/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ./bd-base/conf/hadoop/core-site.xml:/usr/hadoop/etc/hadoop/core-site.xml
#      - ./bd-base/conf/hadoop/yarn-site.xml:/usr/hadoop/etc/hadoop/yarn-site.xml
#      - ./bd-base/conf/spark/spark-defaults.conf:/usr/spark/conf/spark-defaults.conf
    networks:
      bd_net:
        ipv4_address: 10.20.1.3
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"
      - "zookeeper:10.20.1.9"
      - "kafka:10.20.1.10"

  livy:
    image: neoflexdatagram/bd-livy
    build: ./bd-livy
    hostname: livy
    depends_on:
      - master
      - worker1
      - worker2
    volumes:
      - ./livy_batches:/livy_batches
#      - ./bd-base/extralib:/extralib
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/extralib/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/extralib/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/usr/livy/repl_2.12-jars/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/usr/livy/repl_2.12-jars/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
    environment:
      - SPARK_MASTER=yarn
      - SPARK_DEPLOY_MODE=cluster
      # Intentionally not specified - if it's set here, then we can't override it
      # via REST API ("conf"={} map)
      # Can be client or cluster
      #      - SPARK_DEPLOY_MODE=client

      - LOCAL_DIR_WHITELIST=/data/batches/
      - ENABLE_HIVE_CONTEXT=true
      # Defaults are fine for variables below. Uncomment to change them.
    #      - LIVY_HOST=0.0.0.0
    #      - LIVY_PORT=8998
    expose:
      - 1-65535
    ports:
      - 8998:8998
    networks:
      bd_net:
        ipv4_address: 10.20.1.6
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"

  samples:
    image: neoflexdatagram/bd-samples
    build: ./bd-samples
    depends_on:
      - datagram
      - oozie
      - kafka
    volumes:
      - ./tr.url:/tr.url
    networks:
      bd_net:
        ipv4_address: 10.20.1.11
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"

  oozie:
    image: neoflexdatagram/bd-oozie
    build: ./bd-oozie
    hostname: oozie
    depends_on:
      - master
      - worker1
      - worker2
#    volumes:
#      - ./bd-base/extralib:/extralib
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/extralib/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/extralib/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ./bd-oozie/conf/oozie/oozie-site.xml:/usr/oozie/conf/oozie-site.xml
    expose:
      - 1-65535
    ports:
      - 11000:11000
    networks:
      bd_net:
        ipv4_address: 10.20.1.8
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"
      - "oozie:10.20.1.8"

  datagram:
    image: neoflexdatagram/datagram
    build: ./datagram
    hostname: datagram
    depends_on:
      - livy
    env_file: .env
    volumes:
      - ./datagram/keystore.jks:/opt/datagram/keystore.jks
      - ./datagram/gitflow:/opt/datagram/gitflow
      - ./datagram/logs:/opt/datagram/logs
      - ./datagram/mspace:/opt/datagram/mspace
      - ./datagram/application.properties:/opt/datagram/application.properties
      - ./datagram/ldap.properties:/opt/datagram/ldap.properties
#      - ./datagram/entrypoint.sh:/opt/datagram/entrypoint.sh
#      - ../mserver/target/mserver-$VERSION.jar:/opt/datagram/mserver.jar
#      - ../spark2lib/target/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar:/root/.m2/repository/ru/neoflex/meta/etl2/ru.neoflex.meta.etl2.spark.spark2lib/$VERSION/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.jar
#      - ../spark2lib/.flattened-pom.xml:/root/.m2/repository/ru/neoflex/meta/etl2/ru.neoflex.meta.etl2.spark.spark2lib/$VERSION/ru.neoflex.meta.etl2.spark.spark2lib-$VERSION.pom
#      - ../runtime/target/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar:/root/.m2/repository/ru/neoflex/meta/etl/ru.neoflex.meta.etl.spark.runtime/$VERSION/ru.neoflex.meta.etl.spark.runtime-$VERSION.jar
#      - ../runtime/.flattened-pom.xml:/root/.m2/repository/ru/neoflex/meta/etl/ru.neoflex.meta.etl.spark.runtime/$VERSION/ru.neoflex.meta.etl.spark.runtime-$VERSION.pom
#      - ../.flattened-pom.xml:/root/.m2/repository/ru/neoflex/parent/$VERSION/parent-$VERSION.pom
    expose:
      - 1-65535
    ports:
      - 8089:8089
    networks:
      bd_net:
        ipv4_address: 10.20.1.7
    extra_hosts:
      - "master:10.20.1.1"
      - "worker1:10.20.1.2"
      - "worker2:10.20.1.3"
      - "hivemetastore:10.20.1.4"
      - "livy:10.20.1.6"
      - "oozie:10.20.1.8"

  zookeeper:
    image: strimzi/zookeeper:0.11.4-kafka-2.1.0
    command: [
        "sh", "-c",
        "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
      - "2181:2181"
    environment:
      LOG_DIR: /tmp/logs
    networks:
      bd_net:
        ipv4_address: 10.20.1.9

  kafka:
    image: strimzi/kafka:0.18.0-kafka-2.5.0
    command: [
        "sh", "-c",
        "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}"
    ]
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      LOG_DIR: "/tmp/logs"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    networks:
      bd_net:
        ipv4_address: 10.20.1.10
    extra_hosts:
      - "zookeeper:10.20.1.9"

  hue:
    image: gethue/hue:latest
    hostname: hue
    container_name: hue
    ports:
      - "8888:8888"
    volumes:
      - ./hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    depends_on:
      - livy
      - hivemetastore
    networks:
      bd_net:
        ipv4_address: 10.20.1.12

###
networks:
  bd_net:
    ipam:
      driver: default
      config:
        - subnet: 10.20.0.0/16

volumes:
  postgres_data:
  dfs_name:
  dfs_data_1:
  dfs_data_2: