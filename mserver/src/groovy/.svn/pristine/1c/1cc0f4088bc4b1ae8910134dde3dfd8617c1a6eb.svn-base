package MetaServer.rt

import MetaServer.utils.AtlasEntity
import ru.neoflex.meta.utils.Context
import MetaServer.utils.DBConnection
import com.google.common.base.Strings
import groovyx.net.http.ContentType
import org.apache.commons.logging.Log
import org.apache.commons.logging.LogFactory
import org.springframework.core.io.InputStreamResource
import org.springframework.http.HttpStatus
import java.sql.Connection
import MetaServer.utils.REST
import groovy.json.JsonOutput
import groovyx.net.http.RESTClient
import org.apache.http.auth.AuthScope
import org.apache.http.HttpHost

import groovyx.net.http.HTTPBuilder

import org.apache.http.client.config.RequestConfig
import org.apache.http.config.SocketConfig
import org.apache.http.conn.ConnectTimeoutException
import org.apache.http.impl.client.HttpClients
import org.apache.http.client.CredentialsProvider
import org.apache.http.impl.client.BasicCredentialsProvider
import org.apache.http.auth.UsernamePasswordCredentials
import static groovyx.net.http.ContentType.*
import static groovyx.net.http.Method.*


/* protected region MetaServer.rtLivyServer.inport on begin */

import org.springframework.http.ResponseEntity
import ru.neoflex.meta.model.Database

/* protected region MetaServer.rtAtlasScheme.inport end */

class AtlasProject {
    private final static Log logger = LogFactory.getLog(AtlasProject.class)
    /* protected region MetaServer.rtAtlasScheme.statics on begin */
    def static partSize = 100

    private static def evalStep(step, propertyName, scalaSvc, params) {
        def s = step[propertyName]
        def result = [result: true]
        def codePattern = "val jobParameters = Map("
        for(p in params){
            codePattern = codePattern + "\"" + p.name + "\" -> \"" + p.value + "\""
            if(p != params.last()) {
                codePattern = codePattern + ", "
            }
        }
        codePattern = codePattern + ") \n" + 's"""' + s + '"""'
        scalaSvc.eval(codePattern, [], result)
        step[propertyName] = result.value
    }
    
    private static def evalIt(step, scalaSvc, params) {
        if(step.contextFromString == true) {
            evalStep(step, "context", scalaSvc, params)
        }
        if(step._type_ == "etl.TableSource") {
            evalStep(step, "tableName", scalaSvc, params)
        }

        if(step._type_ == "etl.SQLSource") {
            if(step.rdbmsSources != null){
                step.rdbmsSources.eachWithIndex { item, index ->
                    def fakestep = ["rdbmsSource": item] 
                    evalStep(fakestep, "rdbmsSource", scalaSvc, params)
                    step.rdbmsSources[index] = fakestep.rdbmsSource 
                }
            }
            evalStep(step, "statement", scalaSvc, params)
        }
        if (AtlasEntity.isFileEntity(step._type_) || step._type_ == "etl.LocalTarget" ||
                step._type_ == "etl.CSVTarget" || step._type_ == "etl.XMLTarget") {
            evalStep(step, (step._type_ == "etl.LocalTarget" || step._type_ == "etl.LocalSource") ? "localFileName" : "path", scalaSvc, params)
        }
    }
    
    private static importTransformation(transformation, parameters, atlas, db) {
        logger.info("Generate lineage for: " + transformation.name)
        def AtlasEntity sparkProcess = AtlasEntity.createProcessEntity(transformation)
        def inputs = []
        def outputs = []
        
        def sourcesAndTargets = [:]
        def scalaSvc = Context.current.contextSvc.scalaSvc
        for(step in transformation.sources) {
            evalIt(step, scalaSvc, parameters)
            if(AtlasEntity.isFileEntity(step._type_)) {
                def AtlasEntity fileEntity = AtlasEntity.createLocalFileEntity(step, transformation)
                sourcesAndTargets.put(fileEntity.ggetQualifiedName(), fileEntity)
                inputs += ["qualifiedName": fileEntity.ggetQualifiedName(), "typeName": fileEntity.typeName]
            }
            if(step._type_ == "etl.SQLSource" || step._type_ == "etl.TableSource") {
                                    
                def rdbmsSources = []
                def contextName = step.contextFromString == true ? step.contextString : step.context?.name
                if(step._type_ == "etl.SQLSource"){
                    rdbmsSources = step.rdbmsSources
                } else {
                    rdbmsSources.add(step.tableName)
                }
                if(((java.lang.String)rdbmsSources).trim().length() != 0 &&  step.context != null) {
                    def deploymentsList = db.session.createQuery("from rt.Deployment where project.e_id=${atlas.project.e_id} and softwareSystem.name = '${contextName}'").list()
                    if(deploymentsList.size() == 0) {
                        deploymentsList = db.session.createQuery("from rt.Deployment where softwareSystem.name = '${contextName}'").list()
                    }
                    def connectionData = AtlasScheme.initConnectionData("public")
                    if(deploymentsList.size() == 1) {
                        def d = deploymentsList.get(0)
                        AtlasScheme.buildConnectionData(connectionData, d)
                    }
                    rdbmsSources.each {
                        def qualifiedName = it
                        def rdbmsSourceList = AtlasScheme.searchByTypeName(atlas, qualifiedName, AtlasEntity.TypeName.rdbms_table, 0)
                        if(rdbmsSourceList == null) {
                            qualifiedName = AtlasEntity.prepareQualifiedName(connectionData, [it])
                            rdbmsSourceList = AtlasScheme.searchByTypeName(atlas, qualifiedName, AtlasEntity.TypeName.rdbms_table, 0)
                        }
                        
                        for(rdbmsSourcein in rdbmsSourceList) {
                            inputs += ["qualifiedName": qualifiedName, "typeName": AtlasEntity.TypeName.rdbms_table]
                        }
                    }
                } else {
                    def AtlasEntity sqlSourceEntity = AtlasEntity.createTableEntity([host:"sql", port: "sql", databaseProductName: "sql"], step, false)
                    sqlSourceEntity.attributes.description = step.statement
                    sourcesAndTargets.put(sqlSourceEntity.ggetQualifiedName(), sqlSourceEntity)
                    inputs += ["qualifiedName": sqlSourceEntity.ggetQualifiedName(), "typeName": sqlSourceEntity.typeName]
                }
            }
        }
        for(step in transformation.targets) {
            evalIt(step, scalaSvc, parameters)
            if(step._type_ == "etl.LocalTarget") {
                def AtlasEntity fileEntity = AtlasEntity.createLocalFileEntity(step, transformation)
                sourcesAndTargets.put(fileEntity.ggetQualifiedName(), fileEntity)
                outputs += ["qualifiedName": fileEntity.ggetQualifiedName(), "typeName": fileEntity.typeName]
            }
        }

        deleteProcess(atlas, sparkProcess)
        
        AtlasScheme.importData(atlas, [sparkProcess])
        AtlasScheme.importData(atlas, sourcesAndTargets.collect{it.value})
        
        def processList = AtlasScheme.searchByTypeName(atlas, sparkProcess.ggetQualifiedName(), AtlasEntity.TypeName.Process, 0)
        def process = getByGuid(atlas, processList[0].guid)
        
        def processInputs = []
        def processOutputs = []

        for(f in inputs) {
            def fList = AtlasScheme.searchByTypeName(atlas, f.qualifiedName, f.typeName, 0)
            processInputs += ["guid": fList[0].guid, "typeName": f.typeName]
        }
        for(f in outputs) {
            def fList = AtlasScheme.searchByTypeName(atlas, f.qualifiedName, f.typeName, 0)
            processOutputs += ["guid": fList[0].guid, "typeName": f.typeName]
        }
        
        process.entity.relationshipAttributes = null
        
        process.entity.attributes.inputs = processInputs
        process.entity.attributes.outputs = processOutputs

        updateEntity(atlas, process)
    }
    
    public static Object publish(Map entity, Map params = null) {
        
        def db = Database.new
        def atlasProject = db.get(entity)
        def atlas = atlasProject.atlas
        
        def workflowDeplymentsList = db.session.createQuery("select d from rt.WorkflowDeployment d where d.start.project.e_id=${atlasProject.project.e_id}").list() 
        for(wd in workflowDeplymentsList) {            
            def transformationNodes = db.session.createQuery("select n from etl.WFTransformation n where n.workflow.e_id=${wd.start.e_id}").list()
            for(tn in transformationNodes) {
                def transformation = tn.transformation
                def parameters = []
                parameters += wd.parameters
                parameters += tn.parameters
                importTransformation(transformation, parameters, atlas, db)
            }
        }
/*        
        def transformationDeplymentsList = db.session.createQuery("select d from rt.TransformationDeployment d join d.transformation t where d.project.e_id=${atlasProject.project.e_id}").list()        
        
        for(transformationDeploiment in transformationDeplymentsList) {
            def transformation = transformationDeploiment.transformation
            def parameters = transformationDeploiment.parameters
            importTransformation(transformation, parameters, atlas, db)
        }
*/
        logger.info("Finished!")
        return [result: "Finished!"]
    }    
    
    private static deleteProcess(atlas, process) {
        def guids = AtlasScheme.getDeletedGuids(atlas, process.getQueryLikeValue(), [], AtlasEntity.TypeName.Process)
        def guidsToDelete = []
        guids.each {
            def atlasProcess = getByGuid(atlas, it)
            guidsToDelete = atlasProcess?.entity?.attributes.inputs ?: [].plus(atlasProcess?.entity?.attributes.outputs ?: []).collect {
                it.guid
            }
        }
        
        AtlasScheme.bulkDeleteEntities(atlas, guidsToDelete)
        
        AtlasScheme.bulkDeleteEntities(atlas, AtlasScheme.getDeletedGuids(atlas, process.getQueryLikeValue(), [], AtlasEntity.TypeName.Process))
    }
    
    public static deleteRelationship(Map atlas, guid) {
        def resp
        def RESTClient client = REST.getHTTPClient(atlas)
        client.auth.basic(atlas.userName, atlas.password)
        resp = client.delete(
                path : '/api/atlas/v2/relationship/guid/' + guid,
                headers: ["X-Requested-By": InetAddress.getLocalHost().getHostAddress()])?.reader
        resp
    }
        
    public static updateEntity(Map atlas, entity) {
        def resp
        def RESTClient client = REST.getHTTPClient(atlas)
        client.auth.basic(atlas.userName, atlas.password)
        def rb = JsonOutput.toJson(entity)
        resp = client.post(
                path : '/api/atlas/v2/entity/',
                body : rb,
                headers: ["X-Requested-By": InetAddress.getLocalHost().getHostAddress()],
                contentType : groovyx.net.http.ContentType.JSON,
                requestContentType : groovyx.net.http.ContentType.JSON)?.reader
        resp
    }

    public static getByGuid(Map atlas, String guid) {
        def RESTClient client = REST.getHTTPClient(atlas)
        client.auth.basic(atlas.userName, atlas.password)
        def String path = "/api/atlas/v2/entity/guid/" + guid 
        def resp = client.get(           
                path: path
            )?.reader
            
            return resp
    }                
    /* protected region MetaServer.rtAtlasScheme.statics end */
}
