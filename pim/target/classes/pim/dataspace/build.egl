[%
import "execUtils.egl";

var dataset = Dataset.all.first();
var hiveDb = dataset.workspace.name;
var hiveTableName = dataset.shortName;
var expression = interpolateParameters(dataset.expression);
var interpreter = dataset.interpreter;
%]
  import org.apache.spark.sql.DataFrame

  spark.sql("create database if not exists [%=hiveDb%] location '/user/livy/dbs/[%=hiveDb%]'")
  spark.sql("use [%=hiveDb%]")

  def get[%=hiveDb%][%=hiveTableName%]Data(): DataFrame = {
[%if (interpreter.toString() == "SQL") {%]
      spark.sql(s"""[%=expression.trim()%]""")
[%} else if (interpreter.toString() == "SPARK") {%]
      [%=expression.trim()%]
[%}%]
  }
  val result = get[%=hiveDb%][%=hiveTableName%]Data()

[%if (dataset.get("partitionByCols").size > 0) {%]
  result.write.partitionBy([% for (part in dataset.get("partitionByCols")) {%]"[%=part%]"[%if (hasMore){%], [%}%] [%} %]).mode("overwrite").saveAsTable("[%=hiveDb%].[%=hiveTableName%]")
[%} else {%]
  result.write.mode("overwrite").saveAsTable("[%=hiveDb%].[%=hiveTableName%]")
[%}%]            
