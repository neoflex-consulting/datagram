[%
import "execUtils.egl";

var expression = dataset.get("expression");
var interpreter = dataset.get("interpreter");
var hiveDb = dataset.get("workspace").get("name");
var hiveTableName = dataset.get("shortName");
%]
  import org.apache.spark.sql.DataFrame

// начитка датасетов
  spark.sql("create database if not exists [%=hiveDb%] location '/user/livy/dbs/[%=hiveDb%]'")
  spark.sql("use [%=hiveDb%]")
// для link, jdbc - регистрация временных hive view
[%
for (ds in S.allContents()) {
  if (ds.isKindOf(AbstractDataset)) {
    ds.register(ds.shortName);
  }
}
%]

// выполнение кода
  def getData(): DataFrame = {
[%if (interpreter.toString() == "SQL") {%]
      spark.sql("""[%=expression.trim()%]""")
[%} else if (interpreter.toString() == "SPARK") {%]
      [%=expression.trim()%]
[%}%]
  }
  val result = getData()
// сохранение результата как Hive table
[%if (dataset.get("partitionByCols").size > 0) {%]
  result.write.partitionBy([% for (part in dataset.get("partitionByCols")) {%]"[%=part%]"[%if (hasMore){%], [%}%] [%} %]).mode("overwrite").saveAsTable("[%=hiveDb%].[%=hiveTableName%]")
[%} else {%]
  result.write.mode("overwrite").saveAsTable("[%=hiveDb%].[%=hiveTableName%]")
[%}%]            

  val schema = result.schema.json
  val data = result.toJSON.take([%=limit%]).mkString("[", ",", "]")
  println(s"""{"schema":$schema, "data":$data}""")

