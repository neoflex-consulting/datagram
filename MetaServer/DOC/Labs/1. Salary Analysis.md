
# Лабораторная работа № 1
***
Задача: Провести индексацию зарплат с учетом бизнес правил в декабре 2013 года.
***
Бизнес правила:
1. Повышение ЗП максимум 1 раз в год
2. Максимальное повышение ЗП за год - 20%
3. В случае несоблюдения правил 1 или 2, необходимо согласование руководителя компании
***
Что используется при решении:

1. Hive
2. Oozie
3. Livy
4. СУБД postgres (Adventureworks)
5. Schema: humanresources, person
6. Spark SQL
***

Рекомендации:
1. Переключиться на английский язык интерфейса

***

Определения:
1. Поле трансформации - это область, на которой находятся все элементы трансформации

***
## Шаг 1. Анализ задачи
1. На выходе нужны таблицы:
   - Таблица фактов повышения ЗП за предыдущий год
   - Сотрудники, которым требуется согласование руководителя компании для повышения ЗП
   - Сотрудники, которым не требуется согласование руководителя компании для повышения ЗП
2. Разбить по шагам:
   - Подключиться к СУБД
   - Сформировать таблицу повышений за прошедший год 
   - Сформировать таблицы с плановыми повышениями ЗП в следующем году.
3. Необходимые
4. 

## Шаг 2. Создать Project
1. Перейти в раздел Home/ETL/Project
2. Нажать “+” -> Project
3. Заполнить поле Name: labWorks
4. Сохранить

## Шаг 3. Создать Подключение к СУБД
### 3.1. Создать Context
>##### №1
1. Перейти в раздел Home/ETL/JdbcContext
2. Нажать “+” -> JdbcContext
3. Заполнить поле Name: humanresources
4. Сохранить

>##### №2
1. Перейти в раздел Home/ETL/JdbcContext
2. Нажать “+” -> JdbcContext
3. Заполнить поле Name: person
4. Сохранить

### 3.2. Создать Software System
>##### №1
1. Перейти в раздел Home/Connections/SoftwareSystem
2. Нажать “+” -> SoftwareSystem
3. Заполнить поля:
   - Name: humanresources
   - Project: выбрать labWorks
4. Сохранить
   
>##### №2
1. Перейти в раздел Home/Connections/SoftwareSystem
2. Нажать “+” -> Software System
3. Заполнить поля:
   - Name: person
   - Project: выбрать labWorks
4. Сохранить
> Важно! Name в JdbcContext должно совпадать с Name в Software System

> Оставшиеся поля заполнятся автоматически в конце Шага 2

### Шаг 3.3. Создать JdbcConnection
>##### №1
1. Перейти в раздел Home/Connections/JdbcConnection
2. Нажать “+” -> JdbcConnection
3. Заполнить поля 
    - Name: humanresources
    - Project: выбрать labWorks
    - Url: jdbc:postgresql://hivemetastore:5432/Adventureworks
    - Schema: humanresources
    - User: postgres
    - Password: new_password
    - Driver: org.postgresql.Driver
4. Сохранить
5. ![](img/1.%20Salary%20Analysis/молния.PNG) Запустить Test
6. Получить сообщение об успешном соединении: [ "Connected!" ]
7. Закрыть сообщение об ошибке
   
>##### №2
1. Нажать Copy
2. Ввести name: person
3. Заменить поле:
    - Schema: person
4. Сохранить
5. ![](img/1.%20Salary%20Analysis/молния.PNG) Запустить Test
6. Получить сообщение об успешном соединении: [ "Connected!" ]

### Шаг 3.4. Создать Deployment
>##### №1
1. Перейти в раздел Home/Connections/Deployment
2. Нажать “+” -> Deployment
3. Заполнить поля:
    - Name: humanresources
    - Project: выбрать labWorks
    - Connection: Выбрать humanresources
    - Software System: humanresources
4. Сохранить
5. ![](img/1.%20Salary%20Analysis/молния.PNG) Запустить в верхней панели инструментов Refresh Scheme 
6. Получить сообщение об успешном соединении: [ "humanresources_at_humanresources" ]

>##### №2
1. Перейти в раздел Home/Connections/Deployment
2. Нажать “+” -> Deployment
3. Заполнить поля:
   - Name: person
   - Project: выбрать labWorks
   - Connection: Выбрать Person
   - Software System: Person
4. Сохранить
5. ![](img/1.%20Salary%20Analysis/молния.PNG) Запустить Refresh Scheme
6. Получить сообщение об успешном соединении: [ "person_at_person" ]

> Важно! Если при запуске Refresh Scheme возникла ошибка 
> "id to load is required for loading".
> Кнопка сохранить не отработала, нужно нажать её еще раз и повторить запуск Refresh Scheme

### Шаг 3.5. Проверить автоматически созданную Scheme
>##### №1
1. Перейти в раздел Home/Connections/Scheme
2. Проверить наличие humanresources_at_humanresources (Scheme создалась на предыдущем шаге)
3. Перейти в режим редактирования 
4. Развернуть Tables (6 штук)

>##### №2
1. Перейти в раздел Home/Connections/Scheme
2. Проверить наличие person_at_person (Scheme создалась на предыдущем шаге)
3. Перейти в режим редактирования
4. Развернуть Tables (13 штук)

## Шаг 4. Создать Transformation Step1

>##### №1
1. Перейти в раздел Home/ETL/Transformation
2. Нажать “+” -> Transformation
3. Заполнить поля:
   - Name: tr_salary_step1
   - Label: Автоматически подставляется "= Name"
   - Project: выбрать labWorks
   - Spark Version: Выбрать SPARK3
   - Description: Формирование таблицы фактов повышения ЗП за предыдущий год
4. Сохранить

>##### №2
1. ![](img/1.%20Salary%20Analysis/run.PNG) Нажать Run в нижней панели (снизу откроется панель инструментов)
2. Сделать Refresh страницы
3. Перейти в меню слева в autogenerated_tr_tr_salary_step1
4. Прокрутить вниз до пункта Parameters
5. Нажать “+” -> Property (2 раза)
6. Раскрыть первый и заполнить поля:
   - Name: maxRate
   - Value: 20
   - Description: Бизнес правило - Максимальное повышение ЗП на 20% в год
7. Раскрыть второй и заполнить поля:
   - Name: currentDate
   - Value: 2013-12-01
   - Description: Текущая дата для Бизнес правила - Повышение ЗП максимум 1 раз в год
8. Сохранить
9. Вернуться в трансформацию
10. В нижней панели инструментов должны появиться два этих параметра

>##### №3
1. Перетащить на поле иконку из Source:
   - SQL
2. Выбрать её на поле трансформации
3. Справа в Свойствах:
   - Name: humanresources
   - Label: humanresources
   - Context: выбрать humanresources
4. Сохранить

>##### №4
1. Под "SQL humanresources" нажать TXT (Edit SQL)
2. Открылся новый Tab SQL Editor humanresources
3. ![](img/1.%20Salary%20Analysis/tables.PNG) Нажать Table в вехней пенели инструментов
4. Выбрать Table: employeepayhistory
5. Выбрать Fields (через Ctrl):
   - businessentityid (id сотрудника, по нему потом подтянуть ФИО)
   - ratechangedate (дата повышения ЗП)
   - rate (процент повышения ЗП)
6. Нажать синюю кнопку Apply
7. Сгенерируется запрос:
    ```
    select 
       businessentityid,
       ratechangedate,
       rate
   from humanresources.employeepayhistory
    ```
8. Нажать Run*
9. Нажать галочку (Apply)**
10. Закрыть Tab SQL Editor SQL
11. Сохранить

>/* В этот момент: 
> - Под запросом появится чашка кофе
> - Закутиться голубая шестеренка в нижней панели инструментов
> * Запрос отработает, как только:
>  - Шестеренка перестанет крутиться
>  - Появится сообщение о статусе выполнения задачи
>  - Вернется результат запроса

>/** При этим устанавливается структура данных на выходе узла трансформации (в Output Port)

>##### №5
1. Выбрать "SQL humanresources" на поле трансформации
2. Посмотреть, что в свойстве Statement появился запрос
3. Посмотреть, что в свойстве Output Port: OutputPort -> Fields появились 3 поля, которые вернулись из запроса с названием колонок и типом данных (появились в момент отработки Apply)

>##### №6
1. Перетащить на поле трансформации иконку из Transform:
   - Spark SQL
2. Выбрать её
3. Справа в Свойствах:
   - Name: filterSpark
   - Label: filterSpark
   - Sql Ports: 
      - Нажать “+” -> SQLPort
      - Развернуть появившееся поле
      - Заполнить поля:
         - Name: Salary
         - Alias: Salary
4. Соединить "SQL humanresources" и "Spark SQL filterSpark" на поле трансформации
5. Сохранить 

>##### №7
1. Под иконкой Spark нажать TXT (Edit Spark SQL)
2. Открылся новый Tab Spark Editor filterSpark
3. Написать запрос, который возвращает все столбцы из предыдущего шага:
    ```
    select * from Salary
    ```
4. ![](img/1.%20Salary%20Analysis/run.PNG) Нажать Run
5. Нажать галочку (Apply)
6. Сохранить


>##### №8
1. Проанализируем, как нам нужно изменить запрос в "Spark SQL filterSpark" 
2. Нужно добавить к запросу фильтрацию по Бизнес Правилу: Повышение ЗП максимум 1 раз в год
   1.  Используем правило в where в запросе:
    ```
    months_between(cast('${jobParameters("currentDate")}' as date), ratechangedate, true) <= 12
    ```
   2. В нем:
      1. Используется Property currentDate, со вспомогательной функцией jobParameters: '${jobParameters("currentDate")}'
      2. Приводится тип String к Date: cast( ... as date)
      3. Вычисляется разница в месяцах между текущей датой и датой повышения: months_between(..., ..., true)
3. Стереть * из запроса
4. Раскрыть справа меню со столбцами Salary
5. Выбрать поля:
    - businessentityid
    - rate
    - ratechangedate
6. Добавить Where
7. Итоговый запрос выглядит так:
    ```
    select 
       businessentityid,
       rate,
       ratechangedate
   from Salary
   where months_between(cast('${jobParameters("currentDate")}' as date), ratechangedate, true) <= 12
    ```
8. Нажать Run
9. Нажать галочку (Apply)
10. Закрыть Tab Spark Editor filterSpark
11. Сохранить

>##### №9
1. Перетащить на поле трансформации иконку из Source:
   - SQL
2. Выбрать её
3. Справа в Свойствах:
   - Name: person
   - Label: person
   - Context: person
4. Сохранить

>##### №10
1. Под иконкой "SQL person" нажать TXT (Edit SQL)
2. Открылся новый Tab SQL Editor person
3. Написать запрос, который возвращает id сотрудника и его ФИО из таблицы person:
   ```
   select
      businessentityid,
      firstname, 
      middlename,
      lastname
   from person.person
   ```
4. Сохранить
5. Нажать Run
6. Подождать, пока запрос отработает и вернет результат запроса
7. Нажать галочку (Apply) = Сохраняем запрос в SQL
8. Закрыть Tab SQL Editor person
9. Сохранить

>##### №11
1. Перетащить на поле иконку из Transform:
   - Join
2. Соединить её сверху слева со Spark SQL
3. Соединить её снизу слева со SQL
4. Справа в Свойствах:
   - Name: joinSalary
   - Label: joinSalary
   - Join Type: Выбрать LEFT
   - Key Fields: Выбрать businessentityid
   - Joinee Key Fields: Выбрать businessentityid
   - Checkpoint: Поставить True ( true = на этом шаге Spark сохранит промежуточный результат)
5. Сохранить
6. Результат на поле трансформации:
   ![](img/1.%20Salary%20Analysis/Step%204.11.PNG)

>##### №12
1. Под иконкой "Spark joinSalary" нажать TXT (Edit Join)
2. Открылся новый Tab Join Editor joinSalary
3. Обзорно смотрим, что в нем есть:
    - Добавление новой колонки
    - Копирование существующей
    - Изменение порядка колонок
    - Удаление колонки
    - Name: наименование колонки
    - Field Operation Type: тип операции. 
         - Add - проброс поля
         - Transform - выражение на Scala
         - SQL - выражение на Spark SQL
         - Pack - Делает структуру из полей
    - Data Type Domain: тип данный столбца
    - Source Fields: поле, которое возвращается в столбце
      - Если в названии поля стоит _1. - это столбец из 1-ой таблицы
      - Если в названии поля стоит _2. - это столбец из 2-ой таблицы
4. Нажать на "+". Создаем новый столбец с параметрами:
   - Name: personName
   - Field Operation Type: SQL
   - Data Type Domain: String
   - Source Fields: выбрать    _2.firstname, _2.middlename, _2.lastname
   - Expression: concat(_2.firstname, ' ', _2.middlename, ' ', _2.lastname)
5. Нажать галочку (Check)
6. Справа от Expression должно появиться "OK"
7. Удалить столбцы:
   - firstname
   - middlename
   - lastname
8. Сохранить
4. Закрыть Tab Join Editor Join

> Важно! Если Field Operation Type = Add, то Data Type Domain обязательно должен совпадать с типом в поле Source Fields (два последних пункта)

>##### №13
1. Справа сверху навести на плюсик и выбрать Source Editor Code
2. Выбрать:
   - Tab "Step"
   - Select server: db-livy
   - Step: joinSalary (Join)
2. Нажать Load code
3. Нажать Run
4. Подождать, пока запрос отработает и вернет результат
7. В нем столбцы:
   - businessentityid: id сотрудника
   - rate: Процент повышения ЗП
   - ratechangedate: Дата повышения ЗП
   - personName: ФИО сотрудника
8. Таким образом проверить, что запрос отрабатывает корректно.
9. Вернуться на первый Tab Transformation Transformation Designer

>##### №14
1. Перетащить на поле трансформации иконку из Target:
   - CSV
2. Соединить Join с ней 
3. Выбрать её
4. Справа в Свойствах:
   - Name: lastYear
   - Label: lastYear
   - Hdfs: Должен быть выбран True
   - Path: /tmp/salary/lastYear.xls
   - Format: EXCEL
   - Header: Должен быть выбран True
   - EXCEL: 
      - Save Mode: OVERWRITE
5. Сохранить

## Шаг 5. Запустить Transformation Step1

>##### №1
1. Проверить Transformation на ошибки:
   1. ![](img/1.%20Salary%20Analysis/молния.PNG) Запустить в верхней панели инструментов Run/Validate
   2. Получить сообщение об отсутствии ошибок: { "result": true, "problems": [] }
2. ![](img/1.%20Salary%20Analysis/run.PNG) Запустить в нижней панели инструментов Run/Run
3. Получить сообщение об успешном завершении Transformation: Successful run.

>##### №2
1. Выбрать "CSV lastYear" на поле трансформации
2. Под иконкой нажать знак Таблицы (View content)
3. Открылся новый Tab CSV Target Editor CSV
4. Нажать глаз (show)
5. Посмотреть, что внизу закрутилась шестеренка и стала голубой
6. Подождать, пока запрос отработает и вернет результат
7. Это и есть таблица фактов повышения ЗП за предыдущий год


## Шаг 6. Открыть таблицу в HDFS
>##### №1
1. Перейти в раздел Home/Servers/Livy/bd-livy
2. Нажать “+” -> HDFS Console
3. Перейти в /tmp/salary
4. Напротив lastYear нажать Download
5. Открыть скачанный Excel
