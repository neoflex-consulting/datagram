
# Лабораторная работа № 2
***
Задача: Составить гистограмму фактов повышения ЗП с 2008 по 2011 год с шагом в 5%
***
Чему вы научитесь в лабораторной работе: 
1. Использовать Pushdown-оптимизацию в Datagram
2. Создавать параллельные процессы в трансформации

***
Пример использования Pushdown-оптимизации:
1. Предположим, существует запрос на соединение между двумя таблицами
    - В этой операции объединения одна из них представляет собой большую таблицу, а другая - небольшую таблицу с разным количеством разделов, разбросанных по разным узлам кластера (это может быть одна стойка или другая стойка)
    - Spark решает, какие разделы следует объединить в начале (порядок объединения), тип объединения и т. Д. Для лучшей оптимизации.
2. Spark выберет и оптимизирует самый производительный вариант Physical Plan
3. Spark создаст исполняемый код (DAG RDD) для запроса, который необходимо выполнять распределенным образом в кластере  
4. Весь этот процесс известен как Codegen

***
Pushdown-оптимизация:

Блок-схема для Spark запросов:
1. Logical Plan включает в себя три этапа:
    - Parsed Logical Plan ( Unresolved Logical Plan )
    - Analyzed Logical Plan ( Resolved Logical Plan )
    - Optimized Logical Plan
3. Physical Plan

![](img/2.%20Datagram%20Interface/SparkPlane.PNG)


 - Logical Plan - это:
   - Краткое изложение всех шагов преобразования, которые необходимо выполнить в запросе
   - Не предоставляет подробных сведений о драйвере (Master Node) или исполнителе (Worked Node). SparkContext отвечает за его создание и хранение
   - Это помогает нам получить наиболее оптимизированную версию пользовательского выражения

 - Physical Plan - это:
    - Мост между Logical Plan и исполняемым кодом (DAG RDD)
    - Дерево
    - Содержит более конкретное описание того, как должно происходить (исполнение) (конкретный выбор алгоритма)
    - Пользовательские примитивы нижнего уровня (RDD)
***

## Шаг 1. Pushdown-оптимизация

>##### №1
1. Перейти в раздел ![](img/Common/home.PNG) / ETL / Project / labWorks / tr_pushdown
2. Справа сверху навести на плюсик и выбрать Source Code Editor
3. Выбрать:
   - Tab "Step"
   - Select server: db-livy
   - Step: yearLess2012 (Selection)
4. ![](img/Common/load.PNG) Нажать Load code
5. ![](img/Common/run.PNG) Нажать Run
6. Подождать, пока запрос отработает и вернет результат

>##### №2
1. Изменить количество строк данных в результирующей таблице:   
   - В конце кода найти строку:
         ```
     yearLess2012.show(20, false)
         ```
   - Заменить 20 на 200:
         ```
     yearLess2012.show(200, false)
         ```
   - ![](img/Common/run.PNG) Нажать Run
   - Убедиться, что в результате вернулось 200 строк, вместо 20


>##### №3

1. Вывести только физический план запроса:
   - Заменить функцию с show() на explain():
         ```
         yearLess2012.explain()
         ```
   - ![](img/Common/run.PNG) Нажать Run
   - В результирующем поле:
      - Physical Plan

>##### №4

1. Вывести все планы запроса:
   - Заменить функцию с explain() на explain(true):
           ```
           tableFactUp.explain(true)
           ```
   - ![](img/Common/run.PNG) Нажать Run
   - В результирующем поле:
      - Parsed Logical Plan
      - Analyzed Logical Plan
      - Optimized Logical Plan
      - Physical Plan   
    
>##### №5

1. Проанализировать Parsed Logical Plan ( Unresolved Logical Plan )
    ```
    == Parsed Logical Plan ==
    'Filter ('months_between(cast(2012-12-31 as date), 'ratechangedate, true) > 0)
    +- Filter (months_between(cast(cast(2007-01-01 as date) as timestamp), ratechangedate#6731, true, Some(GMT)) < cast(0 as double))
       +- Relation[rate#6730,ratechangedate#6731] JDBCRelation((select
                            rate,
                            ratechangedate
                          from humanresources.employeepayhistory) t) [numPartitions=1]
    
    ```
2. Процесс генерации:
    - Имена столбцов или таблиц могут быть неточными или даже не существовать
    - Spark создает пустой логический план на этом этапе, где нет проверок имени столбца, имени таблицы и т.д.
    - По факту - это черновой вариант будущего Spark запроса "на коленке"
    
>##### №6

1. Проанализировать Analyzed Logical Plan ( Resolved Logical Plan )
    ```
    == Analyzed Logical Plan ==
    rate: decimal(38,18), ratechangedate: timestamp
    Filter (months_between(cast(cast(2012-12-31 as date) as timestamp), ratechangedate#6731, true, Some(GMT)) > cast(0 as double))
    +- Filter (months_between(cast(cast(2007-01-01 as date) as timestamp), ratechangedate#6731, true, Some(GMT)) < cast(0 as double))
        +- Relation[rate#6730,ratechangedate#6731] JDBCRelation((select
                            rate,
                            ratechangedate
                          from humanresources.employeepayhistory) t) [numPartitions=1]
    
    ```
2. Процесс генерации:
    - Начитываются метаданные
    - Определяются типы столбцов (1 строка)

>##### №7

1. Проанализировать Optimized Logical Plan
    ```
    == Optimized Logical Plan ==
    InMemoryRelation [rate#6730, ratechangedate#6731], StorageLevel(memory, deserialized, 1 replicas)
        +- *(1) Filter ((isnotnull(ratechangedate#6731) AND (months_between(1167609600000000, ratechangedate#6731, true, Some(GMT)) < 0.0)) AND (months_between(1356912000000000, ratechangedate#6731, true, Some(GMT)) > 0.0))
            +- InMemoryTableScan [rate#6730, ratechangedate#6731], [isnotnull(ratechangedate#6731), (months_between(1167609600000000, ratechangedate#6731, true, Some(GMT)) < 0.0), (months_between(1356912000000000, ratechangedate#6731, true, Some(GMT)) > 0.0)]
                +- InMemoryRelation [rate#6730, ratechangedate#6731], StorageLevel(memory, deserialized, 1 replicas)
                    +- *(1) Scan JDBCRelation((select
                            rate,
                            ratechangedate
                         from humanresources.employeepayhistory) t) [numPartitions=1] [rate#6730,ratechangedate#6731] PushedFilters: [], ReadSchema: struct<rate:decimal(38,18),ratechangedate:timestamp>
       
    ```
2. Процесс генерации:
    - Spark самостоятельно выполняет оптимизацию через Catalyst Optimizer.
    - Catalyst Optimizer:
        - Проверяет все запросы и этапы трансформации, которые могут быть выполнены вместе
        - Генерирует все возможные варианты порядка выполнения запросов и этапов трансформаций для повышения производительности
        - Оценивая производительность каждого и выбирает наилучший
        - Изменяет последовательность выполнения этапов трансформации для снижения нагрузки и времени отработки запроса
3. В примере:
    - Spark объединил два фильтра в один с помощью оператора "AND"
    - InMemoryRelation - это логический оператор, которые представляет собой кэшированные Dataset
    - InMemoryScans - это стратегия планирования, которая приводит порядок выполнения InMemoryRelation к InMemoryTableScan
    
>##### №8

1. Проанализировать Physical Plan
    ```
    == Physical Plan ==
    InMemoryTableScan [rate#6730, ratechangedate#6731]
        +- InMemoryRelation [rate#6730, ratechangedate#6731], StorageLevel(memory, deserialized, 1 replicas)
            +- *(1) Filter ((isnotnull(ratechangedate#6731) AND (months_between(1167609600000000, ratechangedate#6731, true, Some(GMT)) < 0.0)) AND (months_between(1356912000000000, ratechangedate#6731, true, Some(GMT)) > 0.0))
                +- InMemoryTableScan [rate#6730, ratechangedate#6731], [isnotnull(ratechangedate#6731), (months_between(1167609600000000, ratechangedate#6731, true, Some(GMT)) < 0.0), (months_between(1356912000000000, ratechangedate#6731, true, Some(GMT)) > 0.0)]
                        +- InMemoryRelation [rate#6730, ratechangedate#6731], StorageLevel(memory, deserialized, 1 replicas)
                                +- *(1) Scan JDBCRelation((select
                                rate,
                                ratechangedate
                            from humanresources.employeepayhistory) t) [numPartitions=1] [rate#6730,ratechangedate#6731] PushedFilters: [], ReadSchema: struct<rate:decimal(38,18),ratechangedate:timestamp>
         
    ```
2. Процесс генерации:
    - Физический план - это внутреннее усовершенствование или оптимизация Spark. 
    - После него Spark создаст исполняемый код (DAG RDD) для запроса, который необходимо выполнять распределенным образом в кластере  

3. В примере:
    - Spark объединил два фильтра в один с помощью оператора "AND"